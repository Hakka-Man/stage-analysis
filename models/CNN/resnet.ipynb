{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "        'validation': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    # Todo: Load dataset\n",
    "    dataset_path = '../../train_images'\n",
    "    train_dataset = ImageFolder(root=dataset_path + \"/train\", transform=data_transforms['train'])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "    validation_dataset = ImageFolder(root=dataset_path + \"/validation\", transform=data_transforms['validation'])\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "    classes = (\"1\", \"2\", \"3\", \"4\")\n",
    "    return train_dataset, train_loader, validation_dataset, validation_loader, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    train_loss = 0.0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_accuracy = 100.0 * train_correct / train_total\n",
    "\n",
    "    return model, train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_loader, criterion, device):\n",
    "    validation_loss = 0.0\n",
    "    validation_total = 0\n",
    "    validation_correct = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            validation_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            validation_total += labels.size(0)\n",
    "            validation_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    validation_loss = validation_loss / len(validation_loader.dataset)\n",
    "    validation_accuracy = 100.0 * validation_correct / validation_total\n",
    "\n",
    "    return validation_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model, train_loader, validation_loader, criterion, optimizer, device, num_epochs, save_intervalidation=5):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    validation_losses = []\n",
    "    validation_accuracies = []\n",
    "\n",
    "    classes = (\"1\", \"2\", \"3\", \"4\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        model, train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)\n",
    "        validation_loss, validation_accuracy = validation(model, validation_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        validation_losses.append(validation_loss)\n",
    "        validation_accuracies.append(validation_accuracy)\n",
    "\n",
    "        print(f'Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.2f}%')\n",
    "        print(f'validation Loss: {validation_loss:.4f} - validation Accuracy: {validation_accuracy:.2f}%')\n",
    "        print()\n",
    "\n",
    "        if (epoch + 1) % save_intervalidation == 0:\n",
    "          # Save the model and variables\n",
    "          torch.save(model.state_dict(), f'resnet50_run2_stage_{epoch+1}.pth')\n",
    "          checkpoint = {\n",
    "              'epoch': epoch + 1,\n",
    "              'train_losses': train_losses,\n",
    "              'train_accuracies': train_accuracies,\n",
    "              'validation_losses': validation_losses,\n",
    "              'validation_accuracies': validation_accuracies,\n",
    "              'classes': classes,\n",
    "          }\n",
    "          torch.save(checkpoint, f'resnet50_stage_run2_variables_{epoch+1}.pth')\n",
    "\n",
    "    return model, train_losses, train_accuracies, validation_losses, validation_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses, validation_losses):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_losses)), train_losses, label='Training Loss')\n",
    "    plt.plot(range(len(validation_losses)), validation_losses, label='validationidation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss_plot.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(train_accuracies, validation_accuracies):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_accuracies)), train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(range(len(validation_accuracies)), validation_accuracies, label='validationidation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('accuracy_plot.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(dataset, model, classes):\n",
    "    idx = random.randint(0, len(dataset))\n",
    "    label = dataset[idx][1]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    img = dataset[idx][0].unsqueeze(0).to(device)  # Move the input image tensor to the GPU\n",
    "    model.eval()\n",
    "    #model.to(device)  # Move the model to the GPU\n",
    "    output = model(img)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    # Convert the image and show it\n",
    "    img = img.squeeze().permute(1, 2, 0).cpu()  # Move the image tensor back to the CPU and adjust dimensions\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Predicted: {classes[predicted]}, True: {classes[label]}')\n",
    "    plt.savefig('predicted_image.png')\n",
    "    plt.show()\n",
    "    print(\"Predicted label: \", classes[predicted[0].item()])\n",
    "    print(\"Actual label: \", classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch 1/40\n",
      "Train Loss: 2.0756 - Train Accuracy: 33.82%\n",
      "validation Loss: 1.3506 - validation Accuracy: 35.75%\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m\n\u001b[1;32m     44\u001b[0m save_intervalidation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m---> 45\u001b[0m model, train_losses, train_accuracies, validation_losses, validation_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epochs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_intervalidation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Save the final trained model\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# torch.save(model.state_dict(), f'resnet50_stage_final_model_epochs_{num_epochs}.pth')\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Plot and save the loss and accuracy plots\u001b[39;00m\n\u001b[1;32m     53\u001b[0m plot_loss(train_losses, validation_losses)\n",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m, in \u001b[0;36mtrain_epochs\u001b[0;34m(model, train_loader, validation_loader, criterion, optimizer, device, num_epochs, save_intervalidation)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m model, train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m train(model, train_loader, criterion, optimizer, device)\n\u001b[0;32m---> 12\u001b[0m validation_loss, validation_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     15\u001b[0m train_accuracies\u001b[38;5;241m.\u001b[39mappend(train_accuracy)\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36mvalidation\u001b[0;34m(model, validation_loader, criterion, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 16\u001b[0m validation_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m validation_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Flag to control whether to run training or use saved fine-tuned model.\n",
    "train_model = True\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 4\n",
    "\n",
    "# Import ResNet50 model pretrained on ImageNet\n",
    "model = models.resnet50(weights=None)\n",
    "# print(\"Network before modifying conv1:\")\n",
    "# print(model)\n",
    "\n",
    "# #Modify conv1 to suit CIFAR-10\n",
    "# model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "# Modify the final fully connected layer according to the number of classes\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "# print(\"Network after modifying conv1:\")\n",
    "# print(model)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# Load the dataset\n",
    "# trainset, train_loader, validation_dataset, validation_loader, classes = load_dataset()\n",
    "validation_dataset, validation_loader,trainset, train_loader, classes = load_dataset()\n",
    "\n",
    "if train_model:\n",
    "  # Train the model for 20 epochs, saving every 5 epochs\n",
    "  num_epochs = 40\n",
    "  save_intervalidation = 5\n",
    "  model, train_losses, train_accuracies, validation_losses, validation_accuracies = train_epochs(\n",
    "      model, train_loader, validation_loader, criterion, optimizer, device,\n",
    "      num_epochs, save_intervalidation)\n",
    "\n",
    "  # Save the final trained model\n",
    "  # torch.save(model.state_dict(), f'resnet50_stage_final_model_epochs_{num_epochs}.pth')\n",
    "\n",
    "  # Plot and save the loss and accuracy plots\n",
    "  plot_loss(train_losses, validation_losses)\n",
    "  plot_accuracy(train_accuracies, validation_accuracies)\n",
    "else:\n",
    "  # Load the pre-trained model\n",
    "  model.load_state_dict(torch.load('resnet50_stage_final_model_epochs_50.pth'))\n",
    "  \n",
    "  # Load the variables\n",
    "  checkpoint = torch.load(\"resnet50_stage_variables.pth\")\n",
    "  epoch = checkpoint['epoch']\n",
    "  train_losses = checkpoint['train_losses']\n",
    "  train_accuracies = checkpoint['train_accuracies']\n",
    "  validation_losses = checkpoint['validation_losses']\n",
    "  validation_accuracies = checkpoint['validation_accuracies']\n",
    "  classes = checkpoint['classes']\n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "\n",
    "# Plot and save an example image\n",
    "plot_image(validation_dataset, model, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'resnet50_stage_final_model_epochs_{num_epochs}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
